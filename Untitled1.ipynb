{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8d10704f-efcf-4640-93c4-e6e9a4453b40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Admission Year</th>\n",
       "      <th>Age At Admission</th>\n",
       "      <th>Length of Stay (Days)</th>\n",
       "      <th>Primary Insurance</th>\n",
       "      <th>First Potassium Days From Admit</th>\n",
       "      <th>First Potassium Result</th>\n",
       "      <th>Last Potassium Days From Admit</th>\n",
       "      <th>Last Potassium Result</th>\n",
       "      <th>...</th>\n",
       "      <th>Hx_Vent</th>\n",
       "      <th>Hx_Cath</th>\n",
       "      <th>Hx_Renal_Failure</th>\n",
       "      <th>Hx_Pvd</th>\n",
       "      <th>Hx_Valve_Procedure</th>\n",
       "      <th>Hx_Dm</th>\n",
       "      <th>Hx_Ckd</th>\n",
       "      <th>Hx_Ihd</th>\n",
       "      <th>Hx_Aortic_Valve_Problem</th>\n",
       "      <th>Hx_Prior_Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1616</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>2020</td>\n",
       "      <td>89.039440</td>\n",
       "      <td>6.008976</td>\n",
       "      <td>TBD</td>\n",
       "      <td>0.150694</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.616078</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5717</td>\n",
       "      <td>MALE</td>\n",
       "      <td>2020</td>\n",
       "      <td>69.429830</td>\n",
       "      <td>2.596738</td>\n",
       "      <td>TBD</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2.358333</td>\n",
       "      <td>4.1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5922</td>\n",
       "      <td>MALE</td>\n",
       "      <td>2019</td>\n",
       "      <td>67.465759</td>\n",
       "      <td>2.046528</td>\n",
       "      <td>TBD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2054</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>2019</td>\n",
       "      <td>61.347314</td>\n",
       "      <td>1.644444</td>\n",
       "      <td>TBD</td>\n",
       "      <td>0.033941</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.055349</td>\n",
       "      <td>3.9</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5810</td>\n",
       "      <td>MALE</td>\n",
       "      <td>2019</td>\n",
       "      <td>83.347254</td>\n",
       "      <td>2.253531</td>\n",
       "      <td>TBD</td>\n",
       "      <td>0.278472</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.738194</td>\n",
       "      <td>3.8</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Patient_ID  Gender  Admission Year  Age At Admission  \\\n",
       "0        1616  FEMALE            2020         89.039440   \n",
       "1        5717    MALE            2020         69.429830   \n",
       "2        5922    MALE            2019         67.465759   \n",
       "3        2054  FEMALE            2019         61.347314   \n",
       "4        5810    MALE            2019         83.347254   \n",
       "\n",
       "   Length of Stay (Days) Primary Insurance  First Potassium Days From Admit  \\\n",
       "0               6.008976               TBD                         0.150694   \n",
       "1               2.596738               TBD                         0.112500   \n",
       "2               2.046528               TBD                              NaN   \n",
       "3               1.644444               TBD                         0.033941   \n",
       "4               2.253531               TBD                         0.278472   \n",
       "\n",
       "   First Potassium Result  Last Potassium Days From Admit  \\\n",
       "0                     3.0                        5.616078   \n",
       "1                     3.9                        2.358333   \n",
       "2                     NaN                             NaN   \n",
       "3                     4.2                        0.055349   \n",
       "4                     4.7                        1.738194   \n",
       "\n",
       "   Last Potassium Result  ...  Hx_Vent  Hx_Cath  Hx_Renal_Failure  Hx_Pvd  \\\n",
       "0                    4.0  ...    False    False             False   False   \n",
       "1                    4.1  ...    False    False             False   False   \n",
       "2                    NaN  ...    False    False             False   False   \n",
       "3                    3.9  ...    False    False              True   False   \n",
       "4                    3.8  ...    False    False             False   False   \n",
       "\n",
       "   Hx_Valve_Procedure  Hx_Dm  Hx_Ckd  Hx_Ihd  Hx_Aortic_Valve_Problem  \\\n",
       "0               False  False   False   False                    False   \n",
       "1               False   True   False   False                    False   \n",
       "2               False   True    True   False                    False   \n",
       "3               False   True    True   False                    False   \n",
       "4               False   True   False   False                    False   \n",
       "\n",
       "   Hx_Prior_Admit  \n",
       "0           False  \n",
       "1            True  \n",
       "2            True  \n",
       "3            True  \n",
       "4            True  \n",
       "\n",
       "[5 rows x 95 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data_path = \"data/Training_Set.csv\"\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"data/Training_Set.csv\")\n",
    "\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1da0cf26-cde3-435a-9fe7-2dc1bf11c7a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Most_Common_Value_Prop</th>\n",
       "      <th>NaN_Prop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Primary Insurance</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.042611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max Troponin I Result</th>\n",
       "      <td>0.20296</td>\n",
       "      <td>0.92002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max Troponin I Days From Admit</th>\n",
       "      <td>0.014553</td>\n",
       "      <td>0.918668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Min Troponin I Result</th>\n",
       "      <td>0.247401</td>\n",
       "      <td>0.918668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Min Troponin I Days From Admit</th>\n",
       "      <td>0.008316</td>\n",
       "      <td>0.918668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>First Troponin I Result</th>\n",
       "      <td>0.21822</td>\n",
       "      <td>0.920189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>First Troponin I Days From Admit</th>\n",
       "      <td>0.010417</td>\n",
       "      <td>0.918837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Last Troponin I Result</th>\n",
       "      <td>0.233684</td>\n",
       "      <td>0.919682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Last Troponin I Days From Admit</th>\n",
       "      <td>0.008386</td>\n",
       "      <td>0.919344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hx_Cabg</th>\n",
       "      <td>0.917146</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hx_Hypogly</th>\n",
       "      <td>0.949273</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hx_Vent</th>\n",
       "      <td>0.985796</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hx_Cath</th>\n",
       "      <td>0.998647</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hx_Valve_Procedure</th>\n",
       "      <td>0.947244</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hx_Ihd</th>\n",
       "      <td>0.900575</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Most_Common_Value_Prop  NaN_Prop\n",
       "Primary Insurance                                   1.0  0.042611\n",
       "Max Troponin I Result                           0.20296   0.92002\n",
       "Max Troponin I Days From Admit                 0.014553  0.918668\n",
       "Min Troponin I Result                          0.247401  0.918668\n",
       "Min Troponin I Days From Admit                 0.008316  0.918668\n",
       "First Troponin I Result                         0.21822  0.920189\n",
       "First Troponin I Days From Admit               0.010417  0.918837\n",
       "Last Troponin I Result                         0.233684  0.919682\n",
       "Last Troponin I Days From Admit                0.008386  0.919344\n",
       "Hx_Cabg                                        0.917146       0.0\n",
       "Hx_Hypogly                                     0.949273       0.0\n",
       "Hx_Vent                                        0.985796       0.0\n",
       "Hx_Cath                                        0.998647       0.0\n",
       "Hx_Valve_Procedure                             0.947244       0.0\n",
       "Hx_Ihd                                         0.900575       0.0"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reload the original dataset to analyze the original non-imputed and non-encoded form\n",
    "data_original = pd.read_csv(data_path)\n",
    "\n",
    "# Calculate the proportion of the most common value and NaN values for each column\n",
    "info_summary = pd.DataFrame(index=data_original.columns, columns=['Most_Common_Value_Prop', 'NaN_Prop'])\n",
    "\n",
    "for column in data_original.columns:\n",
    "    most_common_value_prop = data_original[column].value_counts(normalize=True).iloc[0]\n",
    "    nan_prop = data_original[column].isna().mean()\n",
    "    info_summary.loc[column] = [most_common_value_prop, nan_prop]\n",
    "\n",
    "# Identify columns where the most common value proportion is greater than 0.9 or NaN proportion is too high\n",
    "columns_low_info = info_summary[(info_summary['Most_Common_Value_Prop'] > 0.9) | (info_summary['NaN_Prop'] > 0.9)]\n",
    "\n",
    "columns_low_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "50a34da0-c239-4d91-9168-d6b871d00a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Columns to be removed based on the analysis\n",
    "columns_to_remove = columns_low_info.index.tolist()\n",
    "\n",
    "# Remove these columns from the original dataset\n",
    "data_cleaned = data_original.drop(columns=columns_to_remove)\n",
    "\n",
    "# Display the shape of the original and cleaned data to confirm the removal\n",
    "original_shape = data_original.shape\n",
    "cleaned_shape = data_cleaned.shape\n",
    "\n",
    "original_shape, cleaned_shape\n",
    "\n",
    "data = data_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3ae5e466-1efe-417d-b747-a8f6069acdbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4139, 79), (1775, 79), (4139,), (1775,))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Impute missing values\n",
    "# For numerical features, use median\n",
    "numeric_features = data.select_dtypes(include=['int64', 'float64']).columns\n",
    "numeric_transformer = SimpleImputer(strategy='median')\n",
    "data[numeric_features] = numeric_transformer.fit_transform(data[numeric_features])\n",
    "\n",
    "# For categorical features, use the most frequent value\n",
    "categorical_features = data.select_dtypes(include=['object', 'bool']).columns\n",
    "categorical_transformer = SimpleImputer(strategy='most_frequent')\n",
    "data[categorical_features] = categorical_transformer.fit_transform(data[categorical_features])\n",
    "\n",
    "# Encode categorical features\n",
    "label_encoder = LabelEncoder()\n",
    "for column in categorical_features:\n",
    "    data[column] = label_encoder.fit_transform(data[column])\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "# Assuming the last column is the target variable\n",
    "\n",
    "X = data.drop([\"1Yr_Death\"],axis=1)  # Features\n",
    "y = data[\"1Yr_Death\"]  # Target variable\n",
    "# X = X.drop([\"Primary Insurance\"],axis=1)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,stratify=y, random_state=42)\n",
    "\n",
    "# Output the shape of the splits to confirm\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cd058770-b025-449a-b7ce-a2750c32580b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, array([0, 1]))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the target variable is for classification or regression\n",
    "# We'll determine this based on the unique values in the target\n",
    "unique_values_in_target = y.unique()\n",
    "num_unique_values = len(unique_values_in_target)\n",
    "\n",
    "# If the number of unique values is relatively small compared to the number of samples,\n",
    "# and the target is binary or integer, we might be dealing with a classification problem.\n",
    "# Otherwise, it's likely a regression problem.\n",
    "\n",
    "# Let's print the information to decide\n",
    "num_unique_values, unique_values_in_target[:10]  # Display up to 10 unique values to get a sense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c7e7e2c8-6c89-4a8d-87a5-4e67ea9a65da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7509859154929578"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize the RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model on the training set\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4893d6b5-56ad-4490-a197-837ca3b1e8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You should provide test set for use best model. use_best_model parameter has been switched to false value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6649206\ttotal: 10.2ms\tremaining: 10.2s\n",
      "100:\tlearn: 0.3821647\ttotal: 788ms\tremaining: 7.01s\n",
      "200:\tlearn: 0.2690582\ttotal: 1.52s\tremaining: 6.04s\n",
      "300:\tlearn: 0.1860208\ttotal: 2.29s\tremaining: 5.31s\n",
      "400:\tlearn: 0.1354452\ttotal: 3.03s\tremaining: 4.53s\n",
      "500:\tlearn: 0.1013923\ttotal: 3.75s\tremaining: 3.74s\n",
      "600:\tlearn: 0.0766004\ttotal: 4.55s\tremaining: 3.02s\n",
      "700:\tlearn: 0.0600304\ttotal: 5.3s\tremaining: 2.26s\n",
      "800:\tlearn: 0.0489781\ttotal: 6.06s\tremaining: 1.51s\n",
      "900:\tlearn: 0.0390859\ttotal: 6.84s\tremaining: 752ms\n",
      "999:\tlearn: 0.0317900\ttotal: 7.64s\tremaining: 0us\n",
      "Accuracy: 0.7543661971830986\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "cat_model = CatBoostClassifier(iterations=1000, learning_rate=0.1, depth=6, verbose=100)\n",
    "cat_model.fit(X_train, y_train, use_best_model=True)\n",
    "accuracy = cat_model.score(X_test, y_test)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cde058ac-d10e-44e4-a5ba-e7c463a34b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from catboost import CatBoostClassifier\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.impute import SimpleImputer\n",
    "# import pandas as pd\n",
    "\n",
    "# # 假设 data_cleaned 是您已经清理好的DataFrame\n",
    "\n",
    "# # 填充缺失值\n",
    "# numeric_features_cleaned = data_cleaned.select_dtypes(include=['int64', 'float64']).columns\n",
    "# categorical_features_cleaned = data_cleaned.select_dtypes(include=['object']).columns\n",
    "\n",
    "# numeric_transformer_cleaned = SimpleImputer(strategy='median')\n",
    "# data_cleaned[numeric_features_cleaned] = numeric_transformer_cleaned.fit_transform(data_cleaned[numeric_features_cleaned])\n",
    "\n",
    "# categorical_transformer_cleaned = SimpleImputer(strategy='most_frequent', fill_value='missing')\n",
    "# data_cleaned[categorical_features_cleaned] = categorical_transformer_cleaned.fit_transform(data_cleaned[categorical_features_cleaned])\n",
    "\n",
    "# # 分割数据集\n",
    "# X_cleaned = data_cleaned.drop(columns=['1Yr_Death'])  # 假定 '1Yr_Death' 是目标变量\n",
    "# y_cleaned = data_cleaned['1Yr_Death'].astype(int)  # 确保目标变量是整型\n",
    "\n",
    "# X_train_cleaned, X_test_cleaned, y_train_cleaned, y_test_cleaned = train_test_split(\n",
    "#     X_cleaned, y_cleaned, test_size=0.3, random_state=42)\n",
    "\n",
    "# # 训练CatBoost分类器\n",
    "# cat_features_indices = [X_cleaned.columns.get_loc(c) for c in categorical_features_cleaned if c in X_cleaned]\n",
    "\n",
    "# cat_model = CatBoostClassifier(iterations=1000, learning_rate=0.1, depth=6, cat_features=cat_features_indices, verbose=100)\n",
    "# cat_model.fit(X_train_cleaned, y_train_cleaned, eval_set=(X_test_cleaned, y_test_cleaned), use_best_model=True)\n",
    "\n",
    "# # 评估模型\n",
    "# accuracy = cat_model.score(X_test_cleaned, y_test_cleaned)\n",
    "# print(f'Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2eb64d4a-0513-45e7-b093-3d54cf874894",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 假设您的模型保存在'model.pkl'文件中\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2d6a8a40-3f8c-46fb-a64e-da7bd00441b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Hx_Cabg', 'Hx_Hypogly', 'Hx_Vent', 'Hx_Cath', 'Hx_Valve_Procedure', 'Hx_Ihd'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[89], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mlgbm_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/storage1/fs1/andrew.michelson/Active/PGD/Users/m.weiwei/conda/envs/ag/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py:936\u001b[0m, in \u001b[0;36mAbstractModel.predict\u001b[0;34m(self, X, **kwargs)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m    931\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    932\u001b[0m \u001b[38;5;124;03m    Returns class predictions of X.\u001b[39;00m\n\u001b[1;32m    933\u001b[0m \u001b[38;5;124;03m    For binary and multiclass problems, this returns the predicted class labels as a Series.\u001b[39;00m\n\u001b[1;32m    934\u001b[0m \u001b[38;5;124;03m    For regression problems, this returns the predicted values as a Series.\u001b[39;00m\n\u001b[1;32m    935\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 936\u001b[0m     y_pred_proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    937\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m get_pred_from_proba(y_pred_proba\u001b[38;5;241m=\u001b[39my_pred_proba, problem_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproblem_type)\n\u001b[1;32m    938\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m y_pred\n",
      "File \u001b[0;32m/storage1/fs1/andrew.michelson/Active/PGD/Users/m.weiwei/conda/envs/ag/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py:949\u001b[0m, in \u001b[0;36mAbstractModel.predict_proba\u001b[0;34m(self, X, normalize, **kwargs)\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m normalize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    948\u001b[0m     normalize \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalize_pred_probas\n\u001b[0;32m--> 949\u001b[0m y_pred_proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    950\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m normalize:\n\u001b[1;32m    951\u001b[0m     y_pred_proba \u001b[38;5;241m=\u001b[39m normalize_pred_probas(y_pred_proba, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproblem_type)\n",
      "File \u001b[0;32m/storage1/fs1/andrew.michelson/Active/PGD/Users/m.weiwei/conda/envs/ag/lib/python3.8/site-packages/autogluon/tabular/models/lgb/lgb_model.py:256\u001b[0m, in \u001b[0;36mLGBModel._predict_proba\u001b[0;34m(self, X, num_cpus, **kwargs)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_predict_proba\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, num_cpus\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 256\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    258\u001b[0m     y_pred_proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mpredict(X, num_threads\u001b[38;5;241m=\u001b[39mnum_cpus)\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproblem_type \u001b[38;5;241m==\u001b[39m REGRESSION:\n",
      "File \u001b[0;32m/storage1/fs1/andrew.michelson/Active/PGD/Users/m.weiwei/conda/envs/ag/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py:398\u001b[0m, in \u001b[0;36mAbstractModel.preprocess\u001b[0;34m(self, X, preprocess_nonadaptive, preprocess_stateful, **kwargs)\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;124;03mPreprocesses the input data into internal form ready for fitting or inference.\u001b[39;00m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;124;03mIt is not recommended to override this method, as it is closely tied to multi-layer stacking logic. Instead, override `_preprocess`.\u001b[39;00m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m preprocess_nonadaptive:\n\u001b[0;32m--> 398\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_preprocess_nonadaptive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m preprocess_stateful:\n\u001b[1;32m    400\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preprocess(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/storage1/fs1/andrew.michelson/Active/PGD/Users/m.weiwei/conda/envs/ag/lib/python3.8/site-packages/autogluon/tabular/models/lgb/lgb_model.py:283\u001b[0m, in \u001b[0;36mLGBModel._preprocess_nonadaptive\u001b[0;34m(self, X, is_train, **kwargs)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_preprocess_nonadaptive\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, is_train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 283\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_preprocess_nonadaptive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_train:\n\u001b[1;32m    286\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_requires_remap \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/storage1/fs1/andrew.michelson/Active/PGD/Users/m.weiwei/conda/envs/ag/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py:432\u001b[0m, in \u001b[0;36mAbstractModel._preprocess_nonadaptive\u001b[0;34m(self, X, **kwargs)\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;66;03m# TODO: In online-inference this becomes expensive, add option to remove it (only safe in controlled environment where it is already known features are present\u001b[39;00m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(X\u001b[38;5;241m.\u001b[39mcolumns) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures:\n\u001b[0;32m--> 432\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X\n",
      "File \u001b[0;32m/storage1/fs1/andrew.michelson/Active/PGD/Users/m.weiwei/conda/envs/ag/lib/python3.8/site-packages/pandas/core/frame.py:3767\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3766\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 3767\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   3769\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3770\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m/storage1/fs1/andrew.michelson/Active/PGD/Users/m.weiwei/conda/envs/ag/lib/python3.8/site-packages/pandas/core/indexes/base.py:5877\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   5874\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   5875\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 5877\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5879\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   5880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   5881\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m/storage1/fs1/andrew.michelson/Active/PGD/Users/m.weiwei/conda/envs/ag/lib/python3.8/site-packages/pandas/core/indexes/base.py:5941\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   5938\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   5940\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 5941\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['Hx_Cabg', 'Hx_Hypogly', 'Hx_Vent', 'Hx_Cath', 'Hx_Valve_Procedure', 'Hx_Ihd'] not in index\""
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9306955-e172-47e4-a88a-a8f1ebb220b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ag",
   "language": "python",
   "name": "ag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
