{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8d10704f-efcf-4640-93c4-e6e9a4453b40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Admission Year</th>\n",
       "      <th>Age At Admission</th>\n",
       "      <th>Length of Stay (Days)</th>\n",
       "      <th>Primary Insurance</th>\n",
       "      <th>First Potassium Days From Admit</th>\n",
       "      <th>First Potassium Result</th>\n",
       "      <th>Last Potassium Days From Admit</th>\n",
       "      <th>Last Potassium Result</th>\n",
       "      <th>...</th>\n",
       "      <th>Hx_Vent</th>\n",
       "      <th>Hx_Cath</th>\n",
       "      <th>Hx_Renal_Failure</th>\n",
       "      <th>Hx_Pvd</th>\n",
       "      <th>Hx_Valve_Procedure</th>\n",
       "      <th>Hx_Dm</th>\n",
       "      <th>Hx_Ckd</th>\n",
       "      <th>Hx_Ihd</th>\n",
       "      <th>Hx_Aortic_Valve_Problem</th>\n",
       "      <th>Hx_Prior_Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1616</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>2020</td>\n",
       "      <td>89.039440</td>\n",
       "      <td>6.008976</td>\n",
       "      <td>TBD</td>\n",
       "      <td>0.150694</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.616078</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5717</td>\n",
       "      <td>MALE</td>\n",
       "      <td>2020</td>\n",
       "      <td>69.429830</td>\n",
       "      <td>2.596738</td>\n",
       "      <td>TBD</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2.358333</td>\n",
       "      <td>4.1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5922</td>\n",
       "      <td>MALE</td>\n",
       "      <td>2019</td>\n",
       "      <td>67.465759</td>\n",
       "      <td>2.046528</td>\n",
       "      <td>TBD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2054</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>2019</td>\n",
       "      <td>61.347314</td>\n",
       "      <td>1.644444</td>\n",
       "      <td>TBD</td>\n",
       "      <td>0.033941</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.055349</td>\n",
       "      <td>3.9</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5810</td>\n",
       "      <td>MALE</td>\n",
       "      <td>2019</td>\n",
       "      <td>83.347254</td>\n",
       "      <td>2.253531</td>\n",
       "      <td>TBD</td>\n",
       "      <td>0.278472</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.738194</td>\n",
       "      <td>3.8</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Patient_ID  Gender  Admission Year  Age At Admission  \\\n",
       "0        1616  FEMALE            2020         89.039440   \n",
       "1        5717    MALE            2020         69.429830   \n",
       "2        5922    MALE            2019         67.465759   \n",
       "3        2054  FEMALE            2019         61.347314   \n",
       "4        5810    MALE            2019         83.347254   \n",
       "\n",
       "   Length of Stay (Days) Primary Insurance  First Potassium Days From Admit  \\\n",
       "0               6.008976               TBD                         0.150694   \n",
       "1               2.596738               TBD                         0.112500   \n",
       "2               2.046528               TBD                              NaN   \n",
       "3               1.644444               TBD                         0.033941   \n",
       "4               2.253531               TBD                         0.278472   \n",
       "\n",
       "   First Potassium Result  Last Potassium Days From Admit  \\\n",
       "0                     3.0                        5.616078   \n",
       "1                     3.9                        2.358333   \n",
       "2                     NaN                             NaN   \n",
       "3                     4.2                        0.055349   \n",
       "4                     4.7                        1.738194   \n",
       "\n",
       "   Last Potassium Result  ...  Hx_Vent  Hx_Cath  Hx_Renal_Failure  Hx_Pvd  \\\n",
       "0                    4.0  ...    False    False             False   False   \n",
       "1                    4.1  ...    False    False             False   False   \n",
       "2                    NaN  ...    False    False             False   False   \n",
       "3                    3.9  ...    False    False              True   False   \n",
       "4                    3.8  ...    False    False             False   False   \n",
       "\n",
       "   Hx_Valve_Procedure  Hx_Dm  Hx_Ckd  Hx_Ihd  Hx_Aortic_Valve_Problem  \\\n",
       "0               False  False   False   False                    False   \n",
       "1               False   True   False   False                    False   \n",
       "2               False   True    True   False                    False   \n",
       "3               False   True    True   False                    False   \n",
       "4               False   True   False   False                    False   \n",
       "\n",
       "   Hx_Prior_Admit  \n",
       "0           False  \n",
       "1            True  \n",
       "2            True  \n",
       "3            True  \n",
       "4            True  \n",
       "\n",
       "[5 rows x 95 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data_path = \"data/Training_Set.csv\"\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"data/Training_Set.csv\")\n",
    "\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1da0cf26-cde3-435a-9fe7-2dc1bf11c7a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Most_Common_Value_Prop</th>\n",
       "      <th>NaN_Prop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Primary Insurance</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.042611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max Troponin I Result</th>\n",
       "      <td>0.20296</td>\n",
       "      <td>0.92002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max Troponin I Days From Admit</th>\n",
       "      <td>0.014553</td>\n",
       "      <td>0.918668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Min Troponin I Result</th>\n",
       "      <td>0.247401</td>\n",
       "      <td>0.918668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Min Troponin I Days From Admit</th>\n",
       "      <td>0.008316</td>\n",
       "      <td>0.918668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>First Troponin I Result</th>\n",
       "      <td>0.21822</td>\n",
       "      <td>0.920189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>First Troponin I Days From Admit</th>\n",
       "      <td>0.010417</td>\n",
       "      <td>0.918837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Last Troponin I Result</th>\n",
       "      <td>0.233684</td>\n",
       "      <td>0.919682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Last Troponin I Days From Admit</th>\n",
       "      <td>0.008386</td>\n",
       "      <td>0.919344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hx_Cabg</th>\n",
       "      <td>0.917146</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hx_Hypogly</th>\n",
       "      <td>0.949273</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hx_Vent</th>\n",
       "      <td>0.985796</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hx_Cath</th>\n",
       "      <td>0.998647</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hx_Valve_Procedure</th>\n",
       "      <td>0.947244</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hx_Ihd</th>\n",
       "      <td>0.900575</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Most_Common_Value_Prop  NaN_Prop\n",
       "Primary Insurance                                   1.0  0.042611\n",
       "Max Troponin I Result                           0.20296   0.92002\n",
       "Max Troponin I Days From Admit                 0.014553  0.918668\n",
       "Min Troponin I Result                          0.247401  0.918668\n",
       "Min Troponin I Days From Admit                 0.008316  0.918668\n",
       "First Troponin I Result                         0.21822  0.920189\n",
       "First Troponin I Days From Admit               0.010417  0.918837\n",
       "Last Troponin I Result                         0.233684  0.919682\n",
       "Last Troponin I Days From Admit                0.008386  0.919344\n",
       "Hx_Cabg                                        0.917146       0.0\n",
       "Hx_Hypogly                                     0.949273       0.0\n",
       "Hx_Vent                                        0.985796       0.0\n",
       "Hx_Cath                                        0.998647       0.0\n",
       "Hx_Valve_Procedure                             0.947244       0.0\n",
       "Hx_Ihd                                         0.900575       0.0"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reload the original dataset to analyze the original non-imputed and non-encoded form\n",
    "data_original = pd.read_csv(data_path)\n",
    "\n",
    "# Calculate the proportion of the most common value and NaN values for each column\n",
    "info_summary = pd.DataFrame(index=data_original.columns, columns=['Most_Common_Value_Prop', 'NaN_Prop'])\n",
    "\n",
    "for column in data_original.columns:\n",
    "    most_common_value_prop = data_original[column].value_counts(normalize=True).iloc[0]\n",
    "    nan_prop = data_original[column].isna().mean()\n",
    "    info_summary.loc[column] = [most_common_value_prop, nan_prop]\n",
    "\n",
    "# Identify columns where the most common value proportion is greater than 0.9 or NaN proportion is too high\n",
    "columns_low_info = info_summary[(info_summary['Most_Common_Value_Prop'] > 0.9) | (info_summary['NaN_Prop'] > 0.9)]\n",
    "\n",
    "columns_low_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "50a34da0-c239-4d91-9168-d6b871d00a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Columns to be removed based on the analysis\n",
    "columns_to_remove = columns_low_info.index.tolist()\n",
    "\n",
    "# Remove these columns from the original dataset\n",
    "data_cleaned = data_original.drop(columns=columns_to_remove)\n",
    "\n",
    "# Display the shape of the original and cleaned data to confirm the removal\n",
    "original_shape = data_original.shape\n",
    "cleaned_shape = data_cleaned.shape\n",
    "\n",
    "original_shape, cleaned_shape\n",
    "\n",
    "data = data_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3ae5e466-1efe-417d-b747-a8f6069acdbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4139, 79), (1775, 79), (4139,), (1775,))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Impute missing values\n",
    "# For numerical features, use median\n",
    "numeric_features = data.select_dtypes(include=['int64', 'float64']).columns\n",
    "numeric_transformer = SimpleImputer(strategy='median')\n",
    "data[numeric_features] = numeric_transformer.fit_transform(data[numeric_features])\n",
    "\n",
    "# For categorical features, use the most frequent value\n",
    "categorical_features = data.select_dtypes(include=['object', 'bool']).columns\n",
    "categorical_transformer = SimpleImputer(strategy='most_frequent')\n",
    "data[categorical_features] = categorical_transformer.fit_transform(data[categorical_features])\n",
    "\n",
    "# Encode categorical features\n",
    "label_encoder = LabelEncoder()\n",
    "for column in categorical_features:\n",
    "    data[column] = label_encoder.fit_transform(data[column])\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "# Assuming the last column is the target variable\n",
    "\n",
    "X = data.drop([\"1Yr_Death\"],axis=1)  # Features\n",
    "y = data[\"1Yr_Death\"]  # Target variable\n",
    "# X = X.drop([\"Primary Insurance\"],axis=1)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,stratify=y, random_state=42)\n",
    "\n",
    "# Output the shape of the splits to confirm\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cd058770-b025-449a-b7ce-a2750c32580b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, array([0, 1]))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the target variable is for classification or regression\n",
    "# We'll determine this based on the unique values in the target\n",
    "unique_values_in_target = y.unique()\n",
    "num_unique_values = len(unique_values_in_target)\n",
    "\n",
    "# If the number of unique values is relatively small compared to the number of samples,\n",
    "# and the target is binary or integer, we might be dealing with a classification problem.\n",
    "# Otherwise, it's likely a regression problem.\n",
    "\n",
    "# Let's print the information to decide\n",
    "num_unique_values, unique_values_in_target[:10]  # Display up to 10 unique values to get a sense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c7e7e2c8-6c89-4a8d-87a5-4e67ea9a65da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7509859154929578"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize the RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model on the training set\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4893d6b5-56ad-4490-a197-837ca3b1e8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You should provide test set for use best model. use_best_model parameter has been switched to false value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6649206\ttotal: 10.2ms\tremaining: 10.2s\n",
      "100:\tlearn: 0.3821647\ttotal: 788ms\tremaining: 7.01s\n",
      "200:\tlearn: 0.2690582\ttotal: 1.52s\tremaining: 6.04s\n",
      "300:\tlearn: 0.1860208\ttotal: 2.29s\tremaining: 5.31s\n",
      "400:\tlearn: 0.1354452\ttotal: 3.03s\tremaining: 4.53s\n",
      "500:\tlearn: 0.1013923\ttotal: 3.75s\tremaining: 3.74s\n",
      "600:\tlearn: 0.0766004\ttotal: 4.55s\tremaining: 3.02s\n",
      "700:\tlearn: 0.0600304\ttotal: 5.3s\tremaining: 2.26s\n",
      "800:\tlearn: 0.0489781\ttotal: 6.06s\tremaining: 1.51s\n",
      "900:\tlearn: 0.0390859\ttotal: 6.84s\tremaining: 752ms\n",
      "999:\tlearn: 0.0317900\ttotal: 7.64s\tremaining: 0us\n",
      "Accuracy: 0.7543661971830986\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "cat_model = CatBoostClassifier(iterations=1000, learning_rate=0.1, depth=6, verbose=100)\n",
    "cat_model.fit(X_train, y_train, use_best_model=True)\n",
    "accuracy = cat_model.score(X_test, y_test)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cde058ac-d10e-44e4-a5ba-e7c463a34b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from catboost import CatBoostClassifier\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.impute import SimpleImputer\n",
    "# import pandas as pd\n",
    "\n",
    "# # 假设 data_cleaned 是您已经清理好的DataFrame\n",
    "\n",
    "# # 填充缺失值\n",
    "# numeric_features_cleaned = data_cleaned.select_dtypes(include=['int64', 'float64']).columns\n",
    "# categorical_features_cleaned = data_cleaned.select_dtypes(include=['object']).columns\n",
    "\n",
    "# numeric_transformer_cleaned = SimpleImputer(strategy='median')\n",
    "# data_cleaned[numeric_features_cleaned] = numeric_transformer_cleaned.fit_transform(data_cleaned[numeric_features_cleaned])\n",
    "\n",
    "# categorical_transformer_cleaned = SimpleImputer(strategy='most_frequent', fill_value='missing')\n",
    "# data_cleaned[categorical_features_cleaned] = categorical_transformer_cleaned.fit_transform(data_cleaned[categorical_features_cleaned])\n",
    "\n",
    "# # 分割数据集\n",
    "# X_cleaned = data_cleaned.drop(columns=['1Yr_Death'])  # 假定 '1Yr_Death' 是目标变量\n",
    "# y_cleaned = data_cleaned['1Yr_Death'].astype(int)  # 确保目标变量是整型\n",
    "\n",
    "# X_train_cleaned, X_test_cleaned, y_train_cleaned, y_test_cleaned = train_test_split(\n",
    "#     X_cleaned, y_cleaned, test_size=0.3, random_state=42)\n",
    "\n",
    "# # 训练CatBoost分类器\n",
    "# cat_features_indices = [X_cleaned.columns.get_loc(c) for c in categorical_features_cleaned if c in X_cleaned]\n",
    "\n",
    "# cat_model = CatBoostClassifier(iterations=1000, learning_rate=0.1, depth=6, cat_features=cat_features_indices, verbose=100)\n",
    "# cat_model.fit(X_train_cleaned, y_train_cleaned, eval_set=(X_test_cleaned, y_test_cleaned), use_best_model=True)\n",
    "\n",
    "# # 评估模型\n",
    "# accuracy = cat_model.score(X_test_cleaned, y_test_cleaned)\n",
    "# print(f'Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb64d4a-0513-45e7-b093-3d54cf874894",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import lightgbm as lgb\n",
    "\n",
    "# 假设您的模型保存在'model.pkl'文件中\n",
    "model_filename = '/AutogluonModels/ag-20240316_035635/models/LightGBM/model.pkl'\n",
    "\n",
    "# 加载模型\n",
    "with open(model_filename, 'rb') as file:\n",
    "    lgbm_model = pickle.load(file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ag",
   "language": "python",
   "name": "ag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
